from bs4 import BeautifulSoup
import urllib
import re
import json
from textblob import TextBlob
import langid

# words that can charaterize json ClaimReview which I'd like to find
MAIN_KEYWORD = "Generated by Full Fact Claim Review Schema"
JSON_KEYWORD = [ "claimReviewed", "itemReviewed", "reviewRating" ]
#JSON_KEYWORD = ["ciaoo"]

# todo

def get_url_to_process():
  url_to_connect = "https://www.agcom.it/siti-di-fact-checking"
  url_array = []

  html_page = urllib.request.urlopen(url_to_connect)
  soup = BeautifulSoup(html_page)

  # "a" is the tag that have a link
  all_urls = soup.find_all("div").find_all("a")
  
  print(all_urls)
  for link in all_urls:
      href=link.get('href')
    
      if href:
          if r"agcom.it" in href:    #internal link
              continue
         
          elif href[0]=="#":   #same page target link   
              continue
            
          else:                       #external link
              url_array.append(href)

  print("stampo")
  print(url_array)
  return url_array


# return an array with all url to examine
def get_url_to_process_try_function():
  url1 = "https://facta.news/fuori-contesto/2022/09/27/eventi-avversi-eudravigilance-minori/"
  url2 = "https://facta.news/fuori-contesto/2022/10/13/pfizer-testato-trasmissione-covid/"

  url_array = []
  url_array.append(url1)
  url_array.append(url2)

  return url_array

# check if the json has clamReviewd scheme
def check_is_clamReviewed(text):

    for word in text:
        
        for keyword in JSON_KEYWORD:
            if word == keyword:
                return True

    if re.match('<!-- (.*?) -->', MAIN_KEYWORD) == True:
        print("--- comment claimrevieewd json is present but not recognized")
        return True

    return False

# extract language from the html tag, second line of html coed
def extract_language(soup):
  ret = soup.find_all("html")
  language = ret[0].get("lang")
  return language

# read from html code if it's present a json_file, in case return the json_claimReviewed
def read_from_web(url):

    # I  extract all possible json, and the language. 

    html_page = urllib.request.urlopen(url)
    soup = BeautifulSoup(html_page)
    json_html = soup.find_all("script",type="application/ld+json")
    language = extract_language(soup)

    # I bring all json in an array 
    all_json = []
    for th in json_html:
        all_json.append(str(th))

    # I split every json and check if they contain a keyword
    claim_review = ''
    for j in all_json:
        splitted_json = j.split('"')
        if check_is_clamReviewed( splitted_json ) == True:
            claim_review = j

    result = (claim_review,language)
    return result
   
# leave text: <script> and return only the string which the json text, return a better format. Only to have a better format and create the json dictionary 
def extract_json( claim_review_html ):
    step1 = claim_review_html.split("[")
    step2 = step1[1].split("]")
    return step2[0]

# main function which call the others. search for json with claimReviewed scheme
def search_for_json(url):
    claim_review_html, language = read_from_web(url)  

    if claim_review_html == '':
        return ''
    else:
        claim_review_json = extract_json( claim_review_html )

        # convert string in json file
        loaded_json = json.loads( claim_review_json )

        return loaded_json, language


### DEPRECATED ###
# return the language of the page at the url 
def extract_language_type(my_json, url):

  # 2 way to compute language, the first one take title on the article, using indexing, should be better for computation
  # the second one split the url and take the last word of it
  
  try:
    my_string = my_json['claimReviewed']    # here there is the tile of the article
    return langid.classify(my_string)

  except:
    try:
    # leave http word
      my_text = url.split(":")[1] 
  
    # I split to take the last word of the url, which is of the language
      my_text2 = my_text.split("/")

    # I leave the -
      text2_len = len(my_text2)
      my_text3 = my_text2[text2_len - 2].split("-")

    # I create a clean string, the title of the link
      my_string = ''
      for t in my_text3:
        my_string += t + " "

    except:
      print("url: error searching for title an extract language")
      print("at url:" + url)

  
    return langid.classify(my_string)


def main(url_array):

    my_json = {}        # dictionary < url, json_claimReviews >
    my_json_lang = {}   # dictoinary < url, page's language >

    # search json  with claimReviewd scheme on each url
    for url in url_array:
        actual_json = search_for_json(url)

        if actual_json[0] != '':
            my_json[url] = actual_json[0]
            my_json_lang[url] = actual_json[1]
            #my_json_lang[url] = extract_language_type(my_json[url], url)[0]

    if my_json == {}:
      print("--- no json extracted ---")

    # print result
    for k in my_json.keys():
        print("url: " + k)
        print("language: " + my_json_lang[k])
        print(my_json[k])
        print()


######## program start here , modify to choose which array use #####

# url_array = (get_url_to_process() )     # NOT IMPLEMENTED
url_array = (get_url_to_process_try_function())
main(url_array)